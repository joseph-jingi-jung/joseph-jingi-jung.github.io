---
layout: post
title: 만들면서 배우는 생성 AI, 1장
subtitle: 생성 모델링
date: 2024-08-10 23:05:00 +0900
category: content
tags:
  - vision
use_math: true
---

# Takeaways

## 표현학습

- 고차원의 표본공간을 직접 모델링 하는 방식이 아니라 대신 저차원의 잠재공간(latent space)을 사용해 훈련 세트의 각 샘플을 표현하고 이를 원본 공간의 포인트에 매핑.
- 잠재 공간(latent space)의 각 포인트는 어떤 고차원 이미지에 대한 표현입니다.
- 예시가 이해도를 높이는데 도움이 많이 되었다.

```
e.g.) 비스킷 깡통 데이터셋

여러 비스킷 깡통 이미지로 이루어진 훈련 세트로 부터, 깡통의 높이와 너비라는 두 가지 특성으로 깡통을 고유하게 표현.

깡통 세트의 이미지가 고차원 픽셀 공간으로 주어지더라도 각 깡통 이미지를 2차원 잠재 공간의 한 포인트로 변환.

깡통 높이를 키우려면 남재 공간의 높이 차원에 1을 더하고 매핑함수 적용하여 이미지 얻음.
```

- 원본 데이터셋을 간단한 잠재 공간으로 설명할 수 있음을 기계가 깨닫기 쉽지 않음. 이를 딥러닝으로 해결
- 잠재 공간에서 표현 벡터를 조작하여, 이미지의 고수준 속성에 영향을 미치는 연산을 수행.
- 수학적으로 인코더-디코더 기법은 데이터가 놓여 있는 고차원 비선형 매니폴드(manifold)를 샘플링 가능한 단순한 잠재 공간으로 변환.

## 핵심 확률 이론

- 모수 모델링
  - parametric modeling은 안정적인 $p_{model}(x)$ 를 찾는데 사용할 수 있는 기법. 모수 모델은 유한한 개수의 파라미터 $\theta$ 를 사용해 기술 할 수 있는 밀도 함수 $P_{\theta}(x)$의 한 종류.
- 가능도(likelihood)
  - 파라미터 집합 $\theta$ 의 가능도 $L({\theta}|\mathbf{x})$ 는 관측된 포인트 $\mathbf{x}$ 가 주어졌을 때 $\theta$ 의 타당성을 측정하는 함수.
  - $L({\theta}|\mathbf{x}) = p_{\theta}(\mathbf{x})$
  - 관측 포인트 $\mathbf{x}$ 가 주어 졌을 때 $\theta$의 가능도는 포인트 $\mathbf{x}$에서 $\theta$를 파라미터로 가진 밀도 함수의 값으로 정의. 전체 데이터셋 $X$ 에 대해서는 아래와 같음
  - $L(\theta|X) = \underset{x{\in}X}{\prod}p_{\theta}(\mathbf{x})$
- **모수 모델링의 관심은 데이터셋 $X$가 관측될 가능도를 최대화 하는 파라미터 $\hat{\theta}$ 의 최적값을 찾는 것.**

## 밀도 함수를 모델링 하는 방식 세가지

- 명시적으로 밀도 함수를 모델링하지만 밀도 함수를 다루기 쉽도록 (계산가능하게) 모델 제약 (VAE, Diffusion)
- 다루기 쉬운 밀도 함수의 근사치를 명시적으로 모델링 (Normalizing flow model)
- 데이터를 직접 생성하는 확률적 과정을 통해 밀도 함수를 암묵적으로 모델링(GAN)
