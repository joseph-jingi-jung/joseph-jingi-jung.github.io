---
layout: post
title: LDM - High-Resolution Image Synthesis with Latent Diffusion Models
subtitle: latent diffusion
date: 2024-11-18 18:57:08 +0900
category: content
tags:
  - vision
use_math: true
---
Latent diffusion 논문을 읽고 정리한 내용이다.

## Abstract
Diffusion 이 SOTA 성능을 보이지만, Pixel space에서 수행되기 때문에, 학습과 inference에 매우 큰 비용이 소모된다. 성능을 유지하면서, 제한된 환경에서 Diffusion 모델을 학습하기 위해, 이미 학습된 autoencoder의 latent space를 적용하는 것을 제안한다. 또한 모델 아키텍처에 cross-attention layer를 추가함으로써 , 입력을 text, bounding box 등 다양하게 받아 이미지를 생성하게 한다.

## 1. Introduction
앞 부분에는 학습과 Inference에 큰 Computing resource가 필요함을 다시 언급한다. 
### Departure to Latent Space
Diffusion Model은 학습 과정에서 손실항을 최소화 하면서, 의미적으로 무의미한 정보를 억제하면서 그라디언트를 반영하지만, 여전히 불필요한 연산이 많다.  LDM에서는 더 효율적인 생성 모델을 위해, 감지할 수 없는 세부 정보를 제거하는 별도의 mild compression 단계를 추가를 제안한다.
Liklihood 기반 모델에서의 학습은 두단계로 나뉘며, 첫번째는 High-frequency detail을 제거하는 지각적 압축(perceptual compression)이고 두번째는 의미적 데이터를 학습하는 의미적 압축(semantic compression) 단계이다. 이와 의미적으로 동일하나 연산이 더 적합한 공간을 찾는 것을 목표로 하였다.
원본 데이터 공간과 의미적으로 동일한 낮은 차원의 표현 공간(a lower-dimensional representational space)을 제공하는 autoencoder를 학습한다. 학습된 잠재 공간(latent space) 에서 Diffusion model을 훈련하기 때문에, 공간 차원에 대한 더 나은 확장성을 제공하며 과도한 공간 압축에 의존할 필요가 없다.
Autoencoding 단계는 여러 DM 학습과 다른 Task에도 동일하게 재사용 되기 때문에, 한번만 학습하면 되는 장점이 있다. 또한 UNet 백본 네트워크와 Transformer 아키텍처를 연결하여, 임의의 타입을 지원하는 토큰 기반의 컨디셔닝 메커니즘을 설계한다.
이 논문은 다음을 기여한다.
(1) 우리의 방법은 고차원 데이터에서 효율적으로 작동하며, 더 충실한 재구성과 메가픽셀급 고해상도 이미지 생성을 가능하게 함.
(2) 여러 Task에 경쟁력 있는 성능을 보임. inference 코스트를 크게 줄임
(3) 재구성과 생성 능력 간의 섬세한 가중치 조정을 필요로 하지 않음.
(4) SR, Inpainting과 같은 task에서 1024^2 px 수준의 큰 이미지를 생성
(5) cross-attention 기반의 general-purpose 조건 매커니점 설계
(6) Pretrained LDM 과 AE 모델을 배포.

## 3. Method
이미지 space와 peceptually 동일한 공간을 학습하는 Autoencoding을 이용하여, 연산 복잡도를 급격하게 줄임.
(1) 저 차원에서 연산하므로 효율적임
(2) UNet 으로부터 유도된 inductive bias를 활용하며, 이는 공간적 구조를 가진 데이터에 특히 효과적이어서 이전 접근 방식에서 요구되었던 품질 저하를 초래하는 과도한 압축 수준의 필요성을 완화
(3) general-purpose 압축 모델을 얻고, 이를 다양한 생성 모델에 사용할 수 있음.
### 3.1 Perceptual Image Compression
perceptual compression model은 autoencoder를 기반으로 한다. autoencoder는 preceptual loss 와 패치 기반 adversarial objective의 조합으로 학습되었다.

> 참고 
Perceptual Loss는 주로 사전 훈련된 신경망(예: VGG, ResNet)의 특정 레이어에서 추출된 특징(feature maps)을 사용합니다. 원본 이미지와 생성된 이미지의 특징 맵 간의 유사도를 계산하여 손실을 구합니다.
Patch-based Adversarial Objective는 이미지를 전체적으로 평가하지 않고, 이미지를 작은 패치로 나누어 각 패치에 대해 Discriminator를 훈련합니다.
Perceptual Loss는 전반적인 이미지 품질을 보장하고, Patch-based Adversarial Objective는 세부 디테일을 강화.

encoder $\mathcal{E}(x) = z, x \in \mathbb{R}^{H\times W \times 3}, z \in \mathbb{R}^{h \times w \times c}$  decoder $\mathcal{D}(z) = \tilde{x} = \mathcal{D}(\mathcal{E}(x))$ 이고, encoder는 이미지를 downsample 한다.

임의로 높은 분산을 가진 잠재 공간을 방지하기 위해, 2가지 규제를 실험해본다. 첫 번째는 KL-reg 이고, 두번째는 VQ-reg 이다. 
후술 된 DM은 학습된 잠재 공간의 2차원 구조에서 작동하도록 설계 되었기 때문에, 비교적 완만한 압축률을 사용할 수 있으며 매우 우수한 reconstruction을 달성할 수 있다. 다른 이전의 작업들은 임의 순서의 1D 잠재 공간 z를 이용하는 것과 대조적임.

## 3.2 Latent Diffusion Models
encoder, decoder로 구성된 perceptual compression model을 이용하여, High frequency, 구분할 수 없는(imperceptible) detail 정보가 추상화된  저차원 잠재공간 에 접근 할 수 있다. 이 덕분에 (1) 중요한 semantic 정보에 집중할 수 있으며 (2) 저차원 공간 학습으로 효율적이다.
이미지 특화된 inductive biases를 고려한 UNet을 backbone으로 선택함. 기존 백본에서 $x_t$ 대신 $z_t$ 를 이용.

$$
L_{LDM} := \mathbb{E}_{\mathcal{E}(x), \epsilon \sim N(0,1), t} \left[ \Vert \epsilon - \epsilon_\theta(z_t, t) \Vert^2_2 \right]
$$

## 3.3 Conditioning Mechanisms
이미지 생성에 더 유연한 조건을 추가하기 위해, UNet backbone에 cross-attention mechanism을 적용한다. 이는 다양한 형태의 입력으로 하는 attention 기반 모델 적용에 효과적이다.
도메인 특정 인코더(domain specific encoder) $\tau_\theta$ 를 제안한다. 이는 $y$를 intermediate representation $\tau_\theta(y) \in \mathbb{R}^{M \times d_{\tau}}$ 로 매핑한다. 그리고 UNET의 중간 layer에 cross-attention 으로 적용된다. 

$$
\begin{gather}
Attention(Q, K, V) = softmax(\frac{Q K^T}{\sqrt{d}})\cdot V \\
Q = W_Q^{i} \cdot \varphi(z_t), K=W^{(i)}_K \cdot \tau_\theta(y), V=W^{(i)}_V \cdot \tau_\theta(y)\\
\varphi(z_t) \in \mathbb{R}^{N \times d^i_\epsilon}
\end{gather}
$$

$\varphi(z_t)$ 는UNet 의 intermediate represntation의 flatten 을 의미한다.

![image]({{site.url}}/assets/img/ldm-architecture.png)

conditional LDM은 다음 식으로 학습된다.

$$
L_{LDM} := \mathbb{E}_{\mathcal{E}(x), \epsilon \sim N(0,1), t} \left[ \Vert \epsilon - \epsilon_\theta(z_t, t, \tau_\theta(y)) \Vert^2_2 \right]
$$

## 4. Experiments
### 4.1 On perceptual compression trade offs
downsampling factors $f \in {1, 2, 4, 8, 16, 32}$ 로 지정하고 실험
1) LDM-{f1, 2}에 대해 다운샘플링 계수가 작으면 학습 진행 속도가 느려짐
   - 대부분의 perceptual compreession을 diffusion model에 맡김
2) 반대로 f 의 값이 지나치게 크면 비교적 적은 학습 단계 후에 품질 향상이 정체 확인
   - 첫 단계에서의 과도한 압축

$LDM-\{4-8\}$ 이 가장 좋은 결과를 보임

### 4.2 Image Generation with Latent Diffusion
다른 모델과 비교했을 때, 여러 데이터셋에 대하여 전반적으로 결과가 좋았다는 이야기

### 4.3 Conditional Latent Diffusion
#### 4.3.1 Transformer Encoders for LDMs
Text-to-image를 모델링하기 위해, 1.45B KL-regulaized LDM + LAION-400M prompts 로 학습함. BERT-tokenizer를 이용하여, cross-attention 을 수행.
CFG 가 sample quality를 크게 향상.

#### 4.3.2 Convolutional Sampling Beyond $256^2$
Sematic synthesis, super-resolution, inpainting 에도 적용함.
훈련된 input resolution이 256x256 이나,  convolution 방식으로 더 큰 해상도 이미지를 생성할 수 있게 일반화 할 수 있음을 확인
이 응용에서는 SNR이 결과에 상당한 영향을 미침.

### 4.4 Super-Resolution with Latent Diffusion
low-resolution image들을 concatenation 하여 조건으로 사용하여 학습함으로써, SR을 학습. 
저해상도 조건 $y$ 와 UNet의 입력을 연결함. 따라서 $\tau_\theta$ 는 항등 함수(identity)이다.

### 4.5 Inpainting with Latent Diffusion
다른 Inpainting 방식보다 attention 기반 LDM에서의 inpainting이 효과적임을 보인다.

## 5. Limitations & Societal Impact
### Limitations
여전히 GAN 보다 sampling 과정이 느리다.
높은 정밀도가 요구 되는 경우, LDM의 사용이 문제가 될 수 있다. f-4 AE 모델에서 이미지 품질 손실이 매우적지만, 픽셀 공간에서 세밀한 정확성이 필요한 작업에서는 문제가 될 수 있다.
Super resolution 모델은 이미 이러한 측면에서 다소 한계가 있음을 가정.

### Societal Impact
creative 한 활용 방안이 늘어나지만, 반대로 잘못된 정보나 스팸에 악용될 수 있음을 시사.
학습 데이터에 민감한 정보가 포함될 경우 문제가 될 수 있음

## 6. Conclusion
잠재 확산 모델(LDMs)은 훈련과 샘플링 효율을 개선하면서 품질을 유지하는 간단하고 효율적인 방법으로, 다양한 조건부 이미지 합성 작업에서 특정 작업에 맞춘 아키텍처 없이도 최신 기법과 비교해 우수한 성능을 보임.
