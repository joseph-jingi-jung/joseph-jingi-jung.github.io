---
layout: post
title: Understanding Diffusion Models - A Unified Perspective
subtitle: DDPM
date: 2024-09-21 17:13:00 +0900
category: content
tags:
  - vision
use_math: true
---

DDPM이 잘 정리된 논문, Understanding Diffusion Models - A Unified Perspective 을 읽고 작성한 글이다.
후반부의 DDIM, CFG 등의 내용은 추가로 정리하여 작성할 예정이다.

### Hierachical Variational Autoencoders
- HVAE는 VAE를 latent variable을 사용한 여러 계층 구조로 확장시켜 일반화한 모델이다.  
- latent variables themselves are interpreted as generated from other higher-level, more abstract latents.
- T 계층의 HVAE는 각 잠재변수가 이전 모든 잠재변수에 의존하는게 맞으나, 여기서는 이전 잠재변수에만 의존하는 특별한 케이스 MHVAE(Markovian HVAE) 에 집중한다.

### MHVAE(Markovian HVAE)
- 생성 과정이 Markove chain을 모델링하고 있고, 각 잠재변수 $z_t$는 그전 잠재변수 $z_{t+1}$에 의해 생성된다.
- 이를 아래와 같은 수식으로 표현한다.

$$
\begin{aligned}
p(x, z_{1:T}) &= p(z_T)\,p_\theta(x\vert z_1)\prod^T_{t=2}p_\theta(z_{t-1}\vert z_t)
\\ q_\phi(z_{1:T}\vert x) &= q_\phi(z_1\vert x)\prod^T_{t=2}q_\phi(z_t\vert z_{t-1})
\end{aligned}
$$

- 이를 ELBO로 확장하면,

$$
\begin{aligned}
log\,p(x)&=log \int p(x, z_{1:T})dz_{1:T}
\\&= log \int \frac{p(x, z_{1:T}) q_\phi(z_{1:T}\vert x)}{q_\phi(z_{1:T}\vert x)} dz
\\&= log\,\mathbb{E}_{q_\phi(z_{1:T}\vert x)} \left[\frac{p(x, z_{1:T})}{q_\phi(z_{1:T}\vert x)} \right]
\\&\ge \mathbb{E}_{q_\phi(z_{1:T}\vert x)} \left[log \frac{p(x, z_{1:T})} {q_\phi(z_{1:T}\vert x)} \right] \text{(Apply Jensen's Inequality)}
\end{aligned}
$$

- 여기서 맨 마지막 식은 아래와 같이 다시 표현이 가능하다.

$$
\mathbb{E}_{q_\phi(z_{1:T}\vert x)} \left[log \frac{p(x, z_{1:T})} {q_\phi(z_{1:T}\vert x)} \right] = \mathbb{E}_{q_\phi(z_{1:T}\vert x)} \left[ log \frac{p(z_T)p_\theta(x\vert z_1)\prod^T_{t=2}p_\theta(z_{t-1}\vert z_t)}{q_\phi(z_1\vert x)\prod^T_{t=2}q_\phi(z_t\vert z_{t-1})} \right]
$$

### Variational Diffusion Models
- Variational Diffusion Model(VDM)을 가장 쉽게 표현 할 수 있는 방법은 아래 3가지 제약이 있는 Markovian Hierachical Variation Autoencoder 이다.
	- Latent 의 차원은 데이터의 차원과 동일하다.
	- 각 타임스탭의 latent encoder는 학습하는 것이 아니라, 정해진 선형 가우시간 모델을 사용한다. 즉 이전 타임스탭의 출력 중심의 가우시안 분포이다.
	- Latent 인코더의 가우시안 파라미터는 시간에 따라 변화하며, 최종 시간 T에서 latent의 분포는 표준 가우시안이 된다.
- 위 제약을 통해서 몇 가지를 표현할 수 있다.
	- $x_0$ : true data sample
	- $q(x_{1:T}\vert x_0) = \prod^T_{t=1} q(x_t \vert x_{t-1})$
- 우리는 인코더에서 각 잠재 변수의 분포가 이전 계층의 잠재 변수 주변을 중심으로 하는 가우시안 분포라는 것을 알고 있으므로, 파라미터화 한 가우시안 인코더는 아래와 같다.
	- 평균 : $\mu_t(x_t)=\sqrt{\alpha_t}x_{t-1}$
	- 분산 :  $\Sigma_t(x_t)=(1-\alpha_t)I$
	- $q_(x_t\vert x_{t-1}) = N(x_t; \sqrt{\alpha_t}x_{t-1} , (1-\alpha_t)I)$
- 세번째 제약으로 정의할 수 있는 것은 아래와 같다.
	- $p(x_{0:T}) = p(x_T)\prod^T_{t=1}p_\theta(x_{t-1}\vert x_t)$ where $p_(x_T) = N(x_T;0, I)$
- 따라서, $q_(x_t\vert x_{t-1})$는 파라미터 $\phi$ 를 각 시간에 따른 평균과 분산을 가지는 가우시안으로 모델링 할 수 있다.  이로 인해 $p_\theta(x_{t-1}\vert x_t)$ 의 학습에 초점을 맞출 수 있다.
- VDM을 최적화 한 후, 간단한 가우시안 노이즈 인 $p(x_T)$ 에서부터 디노이징 스탭 $p_\theta(x_{t-1}\vert x_t)$ 을 거쳐, 새로운 $x_0$ 를 생성 할 수 있다.
- HVAE처럼, VDM을 ELBO로 나타내면 아래와 같다.

$$
\begin{aligned}
log\,p(x)&=log \int p(x_{0:T})dx_{1:T}
\\&= log \int \frac{p(x_{0:T}) q_\phi(x_{1:T}\vert x_0)}{q_\phi(x_{1:T}\vert x_0)} dx_{1:T}
\\&= log\,\mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[\frac{p(x_{0:T})}{q_\phi(x_{1:T}\vert x_0)} \right]
\\&\ge \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log\,\frac{p(x_{0:T})}{q_\phi(x_{1:T}\vert x_0)} \right]
\\&= \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log \frac{p(x_T)\prod^T_{t=1}p_\theta(x_{t-1}\vert x_t)}{\prod^T_{t=1}q(x_t \vert x_{t-1})} \right]
\\&= \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log \frac{p(x_T)p_\theta(x_0|x_1)\prod^T_{t=2}p_\theta(x_{t-1}\vert x_t)}{q(x_T \vert x_{T-1})\prod^{T-1}_{t=1}q(x_t \vert x_{t-1})} \right]
\\&= \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log \frac{p(x_T)p_\theta(x_0|x_1)\prod^{T-1}_{t=1}p_\theta(x_t\vert x_{t+1})}{q(x_T \vert x_{T-1})\prod^{T-1}_{t=1}q(x_t \vert x_{t-1})} \right]
\\&= \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log \frac{p(x_T)p_\theta(x_0|x_1)}{q(x_T \vert x_{T-1})} \right] + \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} 
\left[log \prod^{T-1}_{t=1} \frac{p_\theta(x_t\vert x_{t+1})}{q(x_t \vert x_{t-1})}\right]
\\&= \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log p_\theta(x_0|x_1) \right] + \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log \frac{p(x_T)}{q(x_T \vert x_{T-1})} \right] + \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} 
\left[\sum^{T-1}_{t=1} log \frac{p_\theta(x_t\vert x_{t+1})}{q(x_t \vert x_{t-1})}\right]
\\&= \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log p_\theta(x_0|x_1) \right] + \mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} \left[log \frac{p(x_T)}{q(x_T \vert x_{T-1})} \right] + \sum^{T-1}_{t=1}\mathbb{E}_{q_\phi(x_{1:T}\vert x_0)} 
\left[ log \frac{p_\theta(x_t\vert x_{t+1})}{q(x_t \vert x_{t-1})}\right]
\\&= \mathbb{E}_{q_\phi(x_1\vert x_0)} \left[log p_\theta(x_0|x_1) \right] + \mathbb{E}_{q_\phi(x_{T-1}, x_T \vert x_0)} \left[log \frac{p(x_T)}{q(x_T \vert x_{T-1})} \right] + \sum^{T-1}_{t=1}\mathbb{E}_{q_\phi(x_{t-1}, x_t, x_{t+1}\vert x_0)} 
\left[ log \frac{p_\theta(x_t\vert x_{t+1})}{q(x_t \vert x_{t-1})}\right] 
\\&\quad \text{(관심 있는 변수만 남기게 단순화)}
\\&= \underbrace{\mathbb{E}_{q_\phi(x_1\vert x_0)} \left[log p_\theta(x_0|x_1) \right]}_{\text{reconstruction term}} - \underbrace{\mathbb{E}_{q(x_{T-1}\vert x_0)}\left[ D_{KL}(q(x_T \vert x_{T-1}) \Vert p(x_T)) \right]}_{\text{prior matching term}}  - \sum^{T-1}_{t=1} \underbrace{\mathbb{E}_{q_\phi(x_{t-1}, x_{t+1}\vert x_0)} 
\left[ D_{KL} (q(x_t \vert x_{t-1}) \Vert p_\theta(x_t \vert x_{t+1}))\right]}_{\text{consistency term}} 
\\ & (x_T \text{​와 } x_t \text{​가 사라지는 KL Divergence 계산에서 직접적으로 필요 없거나 상수로 취급되기 때문})
\end{aligned}
$$

- 첫번째 텀 $E_{q_\phi(x_1\vert x_0)} [log p_\theta(x_0 \vert x_1) ]$ 은 reconstruction term으로 **첫번째 스탭의 latent로 오리지널 데이터를 예측** 하는 로그 likelihood 이다. Vanilla VAE와 유사하게 학습 할 수 있다.
- 두번째 텀 $E_{q(x_{T-1}\vert x_0)}\left[ D_{KL}(q(x_T \vert x_{T-1}) \Vert p(x_T)) \right]$ 은 prior matching term 으로, **마지막 latent 분포가 가우시안 prior 와 동일할 때 최소**화 된다. 그러나 학습 파라미터가 없어 최적화가 불필요하다.  T가 충분히 크면, 이 텀은 자연스럽게 0이 됨을 가정한다.
- 세번째 텀 $E_{q_\phi(x_{t-1}, x_{t+1}\vert x_0)}\left[ D_{KL} (q(x_t \vert x_{t-1}) \Vert p_\theta(x_t \vert x_{t+1}))\right]$은 consistency term 으로, $x_t$ ​에서의 분포를 **정방향과 역방향 과정 모두에서 일관**되게 만들기 위해 노력함. 각 매칭되는 타임 스텝에서 디노이징 스탭과 노이징 스탭의 동일하게 매칭 됨을 의미함. 이 텀은 $p_\theta(x_t \vert x_{t+1})$ 이 가우시안 분포 $q(x_t\vert x_{t-1})$과 동일하게 학습 되었을 때, 최소화 된다.

- 그러나 이 도출된 ELBO를 최적화 하는 것이 최선의 방법은 아닐 수 있음
	- consistency term에는 매 시점에 두 확률 변수 $x_{t-1}, x{t+1}$ 에 대한 기대 값을 계산해야 하는데, 이 과정에서 몬테카를로 추정의 분산이 높아질 수 있음
	- 또한 T-1개의 consistency term의 합으로 계산되어, T가 커질 수록 추정된 ELBO의 분산이 커질 수 있음.

- 따라서 이러한 문제를 해결 하기위해, 한번에 하나의 random variable을 계산하게끔 유도해야함.
	- 마르코비안 성질을 이용해서, $q(x_t \vert x_{t-1})$를 다른 형태로 표현 할 수 있음.
	- Key insight: $q(x_t \vert x_{t-1}) = q(x_t \vert x_{t-1}, x0)$
	- 또한 bayes rule에 의해 아래와 같이 다시 작성할 수 있음

$$
\begin{aligned}
q(x_t \vert_{x-1}, x_0) &= \frac{q(x_{t-1} \vert x_t, x_0) q(x_t \vert x_0)}{ q(x_{t-1} \vert x_0)}
\\
\\& \text{<베이즈 정리>} &
\\
\\P(A\vert B) &= \frac{P(B\vert A)P(A)}{P(B)}
\\
\\P(A\vert B) &= q(x_t \vert_{x-1}, x_0)
\\P(B\vert A) &= q(x_{t-1} \vert x_t, x_0)
\\P(A) &= q(x_t \vert x_0)
\\P(B) &= q(x_{t-1} \vert x_0)
\end{aligned}
$$

- ELBO를 다시 정리해보면,

$$
\begin{aligned}
log\,p(x) &\ge \mathbb{E}_{q(x_{1:T}\vert x_0)} \left[log\,\frac{p(x_{0:T})}{q(x_{1:T}\vert x_0)} \right]
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} \left[log \frac{p(x_T)\prod^T_{t=1}p_\theta(x_{t-1}\vert x_t)}{\prod^T_{t=1}q(x_t \vert x_{t-1})} \right]
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} 
\left[log 
\frac{p(x_T)p_\theta(x_0|x_1)\prod^T_{t=2}p_\theta(x_{t-1}\vert x_t)}
{q(x_1 \vert x_0)\prod^T_{t=2}q(x_t \vert x_{t-1})} 
\right]
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} 
\left[log 
\frac
{p(x_T)p_\theta(x_0|x_1)\prod^T_{t=2}p_\theta(x_{t-1}\vert x_t)}
{q(x_1 \vert x_0)\prod^T_{t=2}q(x_t \vert x_{t-1}, x_0)} 
\right] \text{(by Markovian)}
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} 
\left[
log \frac{p_(x_T)p_\theta(x_0 \vert x_1)}{q(x_1 \vert x_0)} +
log \prod^T_{t=2} \frac{p_\theta(x_{t-1} \vert x_t)}{q(x_t \vert x_{t-1}, x_0)}
\right] \text{(by log property)}
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} 
\left[
log \frac{p_(x_T)p_\theta(x_0 \vert x_1)}{q(x_1 \vert x_0)} +
log \prod^T_{t=2} \frac{p_\theta(x_{t-1} \vert x_t)}
{\frac{q(x_{t-1} \vert x_t, x_0) q(x_t \vert x_0)}{ q(x_{t-1} \vert x_0)}}
\right] \text{(by bayes rule mentioned)}
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} 
\left[
log \frac{p_(x_T)p_\theta(x_0 \vert x_1)}{q(x_1 \vert x_0)} +
log \frac{q(x_1 \vert x_0)}{q(x_T \vert x_0)} +
log \prod^T_{t=2} \frac{p_\theta(x_{t-1} \vert x_t)}
{q(x_{t-1} \vert x_t, x_0)}
\right] \text{(마지막텀 분모 분리))}
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} 
\left[
log \frac{p_(x_T)p_\theta(x_0 \vert x_1)}{q(x_T \vert x_0)} +
log \prod^T_{t=2} \frac{p_\theta(x_{t-1} \vert x_t)}
{q(x_{t-1} \vert x_t, x_0)}
\right] (\text{첫번째, 두번째 텀의 } q(x_1\vert x_0) \text{ 정리)}
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} 
\left[
log \frac{p_(x_T)p_\theta(x_0 \vert x_1)}{q(x_T \vert x_0)} +
\sum^T_{t=2} log \frac{p_\theta(x_{t-1} \vert x_t)}
{q(x_{t-1} \vert x_t, x_0)}
\right]
\\&= \mathbb{E}_{q(x_{1:T}\vert x_0)} \left[log\, p_\theta(x_0 \vert x_1) \right] +
\mathbb{E}_{q(x_{1:T}\vert x_0)}\left[log \frac{p_(x_T)}{q(x_T \vert x_0)}\right] +
\sum^T_{t=2}\mathbb{E}_{q(x_{1:T}\vert x_0)}\left[log \frac{p_\theta(x_{t-1} \vert x_t)}{q(x_{t-1} \vert x_t, x_0)}\right]
\\&= \mathbb{E}_{q(x_1\vert x_0)} \left[log\, p_\theta(x_0 \vert x_1) \right] +
\mathbb{E}_{q(x_T\vert x_0)}\left[log \frac{p_(x_T)}{q(x_T \vert x_0)}\right] +
\sum^T_{t=2}\mathbb{E}_{q(x_t,x_{t-1}\vert x_0)}\left[log \frac{p_\theta(x_{t-1} \vert x_t)}{q(x_{t-1} \vert x_t, x_0)}\right]
\\&= \underbrace{\mathbb{E}_{q(x_1\vert x_0)} \left[log\, p_\theta(x_0 \vert x_1) \right]}_{\text{reconstruction term}} -
\underbrace{D_{KL}(q(x_T\vert x_0) \Vert p(x_T))}_{\text{prior matching term}} -
\sum^T_{t=2}
\underbrace{\mathbb{E}_{q(x_t \vert x_0)}\left[D_{KL}(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t)) \right]}_{\text{denoising matching term}}
\end{aligned}
$$

- ELBO를 정리하면 아래 3가지 독립적인 텀이 된다.
1. reconstruction term 
	- Vanilia VAE의 reconsturction term과 동일. 
	- 몬테카를로 추정으로 최적화

$$
\mathbb{E}_{q(x_1\vert x_0)} \left[log\, p_\theta(x_0 \vert x_1) \right]
$$

2. Prior matching term 
	- $x_0$ 로부터 만들어진 $x_T$가 정규 분포와 얼마나 같은가를 의미. 
	- 학습 파라미터가 없고, 가정에 의해 이 텀은 0이 된다.

$$
D_{KL}(q(x_T\vert x_0) \Vert p(x_T))
$$

3.  **denoising matching term**
	- $p_\theta(x_{t-1} \vert x_t)$ : 현재 노이즈 이미지에서 한 단계 전 이미지로의 전이 확률
	- $q(x_{t-1}\vert x_t, x_0)$ : 노이즈가 있는 이미지($x_t$)에서 이미 최종 결과($x_0$)를 알고 있을 때 그 전 이미지($x_{t-1}$) 로의 전이 확률
	- 이 둘의 KL 발산을 최소화함으로써 두 전이 확률이 최대한 일치되게 학습.

$$
\sum^T_{t=2}\mathbb{E}_{q(x_t \vert x_0)}\left[D_{KL}(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t)) \right]
$$

### Reparameterization trick
- Denoising matching term 

$$
\mathbb{E}_{q(x_t \vert x_0)}\left[D_{KL}(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t)) \right]
$$ 

- 에서 $p_\theta$ 로 샘플링하는 부분이 포함되어있어, 최적화의 어려움이 있다(VAE와 동일) 따라서 여기에도 VAE처럼 Reparameterization trick 적용이 필요하다. 
- $x_t \sim q(x_t \vert x_{t-1})$ 은 아래와 같이 다시 작성 할 수 있다.

$$
\begin{aligned}
q_(x_t\vert x_{t-1}) &= N(x_t; \sqrt{\alpha_t}x_{t-1} , (1-\alpha_t)I) \text{ 이므로, }
\\x_t &= \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t}\epsilon \quad with \,\, \epsilon \sim N(\epsilon; 0, I)
\\x_{t-1} &= \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon \quad with \,\, \epsilon \sim N(\epsilon; 0, I) 
\end{aligned}
$$

- $q(x_t \vert x_0)$ 는 Reparameterization trick을 재귀적으로 적용하여, 유도할 수 있다. 

$$
\begin{aligned}
x_t &= \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t}\epsilon_{t-1}
\\&= \sqrt{\alpha_t} (\sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1}
\\&= \sqrt{\alpha_t}\sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\epsilon_{t-2} + \sqrt{1-\alpha_t}\epsilon_{t-1}
\\&= \sqrt{\alpha_t}\sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}^2 + \sqrt{1-\alpha_t}^2} \epsilon_{t-2} \quad\text{ (두 독립적인 정규분포의 합)}
\\&=\sqrt{\alpha_t\alpha_{t-1}} x_{t-2} + \sqrt{1 -\alpha_t\alpha_{t-1}} \epsilon_{t-2}
\\&=\,...
\\&=\sqrt{\prod^t_{i=1}\alpha_i}\,x_0 + \sqrt{1 - \prod^t_{i=1}\alpha_i}\, \epsilon_0
\\&=\sqrt{\bar{\alpha}_t}\, x_0 + \sqrt{1 - \bar{\alpha}_t}\, \epsilon_0
\\&\sim N\,(x_t; \sqrt{\bar{\alpha}_t}\, x_0, \sqrt{1 - \bar{\alpha}_t}\, I)
\end{aligned}
$$

> 참고 : 두 독립적인 정규분포의 합

$$
\begin{aligned}
X &\sim N(\mu_X, \sigma^2_X)
\\Y &\sim N(\mu_Y, \sigma^2_Y)
\\Z &= X+Y\text{, then}
\\Z &\sim N(\mu_X + \mu_Y, \sigma^2_X + \sigma^2_Y)
\end{aligned}
$$

### $q(x_{t-1} \vert x_t, x_0)$ 의 표현
- $q(x_t\vert x_0)$와 $q(x_{t-1}\vert x_0)$ 을 유도하였으므로, $q(x_{t-1} \vert x_t, x_0)$를 Bayes rule 을 이용해서 유도해보자.

$$
\begin{aligned}
q(x_{t-1} \vert x_t, x_0) &= \frac{q(x_t \vert x_{t-1}, x_0) q(x_{t-1} \vert x_0)}{ q(x_t \vert x_0)} \text{ (by Bayes rule)}
\\&= \frac
{N(x_t; \sqrt{\alpha_t}x_{t-1}, (1-\alpha_t)I) \, N\,(x_{t-1}; \sqrt{\bar{\alpha}_{t-1}}\, x_0, \sqrt{1 - \bar{\alpha}_{t-1}}\, I)}
{N\,(x_t; \sqrt{\bar{\alpha}_t}\, x_0, \sqrt{1 - \bar{\alpha}_t}\, I)}
\\& \propto exp \left\{ 
-\left[
\frac{(x_t - \sqrt{\alpha_t} x_{t-1})^2}{2(1-\alpha_t)}
+ \frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_0)^2}{2(1-\bar{\alpha}_{t-1})}
- \frac{(x_{t} - \sqrt{\bar{\alpha}_{t}} x_0)^2}{2(1-\bar{\alpha}_{t})}
\right]
\right\}
\\ &\text{( by } N(x; \mu, \sigma^2) = \frac{1}{\sigma\sqrt{2\pi}}exp\left[-\frac{(x-\mu)^2}{2\sigma^2} \right] \text{ ) 에서 앞에부분 생략, 비례로 정의}
\\& = exp \left\{ 
- \frac 1 2 \left[
\frac{(x_t - \sqrt{\alpha_t} x_{t-1})^2}{1-\alpha_t}
+ \frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_0)^2}{1-\bar{\alpha}_{t-1}}
- \frac{(x_{t} - \sqrt{\bar{\alpha}_{t}} x_0)^2}{1-\bar{\alpha}_{t}}
\right]
\right\}
\\& = exp \left\{ 
- \frac 1 2 \left[
\frac{(-2\sqrt{\alpha_t} x_t x_{t-1} + \alpha_t x^2_{t-1}) }{1-\alpha_t}
+ \frac{(x^2_{t-1} - 2\sqrt{\bar{\alpha}_{t-1}}x_{t-1}x_0)}{1-\bar{\alpha}_{t-1}}
+ C(x_t, x_0)
\right]
\right\}
\\&\,(\,q(x_{t-1} \vert x_t, x_0)\text{는 주어진} x_t\text{와 } x_0 \text{에 대하여,  }x_{t-1} \text{을 계산 하므로, } x_t, x_0 \text{만 포함된 항은 상수 항으로 간주} )
\\& \propto exp \left\{ 
- \frac 1 2 \left[
- \frac{2\sqrt{\alpha_t} x_t x_{t-1} }{1-\alpha_t}
+ \frac{\alpha_t x^2_{t-1}}{1-\alpha_t}
+ \frac{x^2_{t-1}}{1-\bar{\alpha}_{t-1}}
- \frac{2\sqrt{\bar{\alpha}_{t-1}}x_{t-1}x_0}{1-\bar{\alpha}_{t-1}}
\right]
\right\}
\\& = exp \left\{ 
- \frac 1 2 \left[
\left(\frac{\alpha_t}{1-\alpha_t} + \frac{1}{1-\bar{\alpha}_{t-1}} \right) x^2_{t-1}
- 2\left( \frac{\sqrt{\alpha_t} x_t }{1-\alpha_t}  
+ \frac{\sqrt{\bar{\alpha}_{t-1}}x_0}{1-\bar{\alpha}_{t-1}}\right) x_{t-1}
\right]
\right\}
\\& = exp \left\{ 
- \frac 1 2 \left[
\left(\frac{\alpha_t(1-\bar{\alpha}_{t-1}) + (1-\alpha_t)}{(1-\alpha_t)(1-\bar{\alpha}_{t-1})} \right) x^2_{t-1}
- 2\left( \frac{\sqrt{\alpha_t} x_t }{1-\alpha_t}  
+ \frac{\sqrt{\bar{\alpha}_{t-1}}x_0}{1-\bar{\alpha}_{t-1}}\right) x_{t-1}
\right]
\right\}
\\& = exp \left\{ 
- \frac 1 2 \left[
\left(\frac{1-\bar{\alpha}_t}{(1-\alpha_t)(1-\bar{\alpha}_{t-1})} \right) x^2_{t-1}
- 2\left( \frac{\sqrt{\alpha_t} x_t }{1-\alpha_t}  
+ \frac{\sqrt{\bar{\alpha}_{t-1}}x_0}{1-\bar{\alpha}_{t-1}}\right) x_{t-1}
\right]
\right\}
\\& = exp \left\{ 
- \frac 1 2 \left(\frac{1-\bar{\alpha}_t}{(1-\alpha_t)(1-\bar{\alpha}_{t-1})} \right) \left[
 x^2_{t-1}
- 2 \frac{\left( \frac{\sqrt{\alpha_t} x_t }{1-\alpha_t}  
+ \frac{\sqrt{\bar{\alpha}_{t-1}}x_0}{1-\bar{\alpha}_{t-1}}\right)}
{\left(\frac{1-\bar{\alpha}_t}{(1-\alpha_t)(1-\bar{\alpha}_{t-1})} \right)} x_{t-1}
\right]
\right\}
\\& = exp \left\{ 
- \frac 1 2 \left(\frac{1-\bar{\alpha}_t}{(1-\alpha_t)(1-\bar{\alpha}_{t-1})} \right) \left[
 x^2_{t-1}
- 2 \frac{\left( \frac{\sqrt{\alpha_t} x_t }{1-\alpha_t}  
+ \frac{\sqrt{\bar{\alpha}_{t-1}}x_0}{1-\bar{\alpha}_{t-1}}\right)(1-\alpha_t)(1-\bar{\alpha}_{t-1})}
{\left(1-\bar{\alpha}_t \right)} x_{t-1}
\right]
\right\}
\\& = exp \left\{ 
- \frac 1 2 \left(\frac{1-\bar{\alpha}_t}{(1-\alpha_t)(1-\bar{\alpha}_{t-1})} \right) \left[
 x^2_{t-1}
- 2 \frac{ 
\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) x_0}
{\left(1-\bar{\alpha}_t \right)} x_{t-1}
\right]
\right\}
\\& \propto exp \left\{ 
- \frac 1 2 \left(\frac{1}{\frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}} \right) \left[\left(
 x_{t-1}
- \frac{ 
\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) x_0}
{\left(1-\bar{\alpha}_t \right)}
\right)^2\right]
\right\}
\\&= N(x_{t-1}; \underbrace{\frac{ 
\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) x_0}
{\left(1-\bar{\alpha}_t \right)}}_{\mu_q(x_t, x_0)}, \underbrace{\frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t} I}_{\Sigma_q(t)}) \quad \text{( by 정규분포 p.d.f)}
\end{aligned}
$$

-  따라서, $x_{t-1} \sim q(x_{t-1}\vert x_t, x_0)$ 이 정규분포를 따르고, 그 평균이 $x_t, x_0$로 구성된 함수 $\mu(x_t, x_q)$ 이고, 분산이 $\alpha$로 구성된 $\Sigma_q(t)$ 임을 알 수 있다.
- 여기서 $\alpha$는 $t$에 따라 고정되어 있고, 이는 hyperparameters로 정의 된다.
- 분산 $\Sigma_q(t)=\sigma^2_q(t)I$ 로 다시 쓸 수 있고, 아래와 같이 다시 쓸 수 있다.

$$
\sigma^2_q(t) = \frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}
$$

### ELBO의 $D_{KL}(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t))$ 의 연산
- 위에서 ground-truth $q(x_{t-1}\vert x_t, x_0)$이 정규분포를 따름을 확인하였고, $p_\theta(x_{t-1}\vert x_t)$ 이 그와 가장 가까워져야 한다.
- 따라서 $p_\theta(x_{t-1}\vert x_t)$ 를 정규 분포로 가정하며, GT의 분산이 시간에 따라 고정되어있기 때문에, 동일한 분산으로 가정한다. 자세한 이유는 아래와 같다.
	- 계산의 단순화: 공분산을 모델이 학습하도록 하는 대신, 고정된 값을 사용하면 계산이 훨씬 단순해집니다. KL-발산에서 공분산 항을 제거할 수 있기 때문에, 모델은 주로 평균($\mu_\theta$)에만 집중하여 학습할 수 있습니다.
	- 효율적인 학습: 공분산($\Sigma_q(t)$)는 정방향 과정에서 이미 결정된 값으로, 노이즈가 시간에 따라 추가되면서 증가하거나 변하는 양상을 갖습니다. 이를 역방향 과정에서 고정함으로써, 모델은 데이터의 복원 과정에서 필요한 중요한 정보인 평균만 학습하는 데 집중할 수 있습니다.
	- 정확한 근사: $p_\theta(x_{t−1}\vert x_t)$에서 공분산을 $\Sigma_q(t)$로 설정하면, 역방향 과정의 참된 분포 $q(x_{t-1}\vert x_t, x_0)$와 구조적으로 매우 유사하게 만들어, 근사를 보다 쉽게 수행할 수 있습니다. 이로 인해 모델이 학습하기 쉽고, 실제로 좋은 성능을 보입니다.
- 따라서 KL Divergence를 다시 작성해보면 아래와 같다.

$$
\begin{aligned}
&\underset{\theta}{argmin}\,D_{KL}\,(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t))
\\ &= \underset{\theta}{argmin}\,D_{KL} (N(x_{t-1}; \mu_q, \Sigma_q(t)) \Vert N(x_{t-1};\mu_\theta, \Sigma_q(t)))
\\ &= \underset{\theta}{argmin}\, \frac 1 2 \left[log\,\frac{\vert \Sigma_q(t) \vert}{\vert \Sigma_q(t) \vert} - d + tr(\Sigma_q(t)^{-1}\Sigma_q(t)) + (\mu_\theta - \mu_q)^T\Sigma_q(t)^{-1}(\mu_\theta - \mu_q) \right]
\\ &= \underset{\theta}{argmin}\, \frac 1 2 \left[log\,1 - d + d + (\mu_\theta - \mu_q)^T\Sigma_q(t)^{-1}(\mu_\theta - \mu_q) \right]
\\ &= \underset{\theta}{argmin}\, \frac 1 2 \left[(\mu_\theta - \mu_q)^T\Sigma_q(t)^{-1}(\mu_\theta - \mu_q) \right]
\\ &= \underset{\theta}{argmin}\, \frac 1 2 \left[(\mu_\theta - \mu_q)^T{(\sigma^2_q(t)I)}^{-1}(\mu_\theta - \mu_q) \right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \left[(\mu_\theta - \mu_q)^T(\mu_\theta - \mu_q) \right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \left[\Vert \mu_\theta - \mu_q \Vert^2_2\right]
\end{aligned}
$$

- $\mu_q$ 는 $\mu_q(x_t, x_0)$ 를 짧게 쓴 것이고, $\mu_\theta$는 $\mu_\theta(x_t, t)$ 를 간결하게 쓴것이므로,  $\mu_\theta(x_t, t)$ 가 $\mu_q(x_t, x_0)$  에 가깝게 최적화 하는 것이 목적이다.
- 여기서 $\mu_q(x_t, x_0)$ 는 아래와 같고

$$
\frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) x_0}{\left(1-\bar{\alpha}_t \right)}
$$

- 여기서 $\alpha_t$ 와 $x_t$는 이미 주어진 값이고, 여기서 $x_0$ 만이 생성 과정에서 모르는 값이기 때문에 이 부분만 대체하여 학습 효율성을 높인다. 따라서 $\mu_\theta(x_t, t)$ 를 다시 써보면 아래와 같다. $\hat{x}_\theta$ 는 $x_t, t$를 입력으로 받는 신경망이다.

$$
\mu_\theta(x_t, t) = \frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) \hat{x}_\theta(x_t, t)}{\left(1-\bar{\alpha}_t \right)}
$$

- 다시 최적화 문제를 간단하게 표현해보면, 아래와 같다.

$$
\begin{aligned}
&\underset{\theta}{argmin}\,D_{KL}\,(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t))
\\ &= \underset{\theta}{argmin}\,D_{KL} (N(x_{t-1}; \mu_q, \Sigma_q(t)) \Vert N(x_{t-1};\mu_\theta, \Sigma_q(t)))
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \left[\Vert \mu_\theta - \mu_q \Vert^2_2\right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \left[\left\Vert 
\frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) \hat{x}_\theta(x_t, t)}{\left(1-\bar{\alpha}_t \right)} - \frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) x_0}{\left(1-\bar{\alpha}_t \right)}
\right\Vert^2_2\right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \left[\left\Vert 
\frac{\sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) \hat{x}_\theta(x_t, t)}{\left(1-\bar{\alpha}_t \right)} - \frac{\sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) x_0}{\left(1-\bar{\alpha}_t \right)}
\right\Vert^2_2\right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \left[\left\Vert 
\frac{\sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t)}{\left(1-\bar{\alpha}_t \right)}( \hat{x}_\theta(x_t, t) - x_0)
\right\Vert^2_2\right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \frac{\sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t)}{\left(1-\bar{\alpha}_t \right)} \left[\left\Vert 
\hat{x}_\theta(x_t, t) - x_0
\right\Vert^2_2\right]
\end{aligned}
$$

- **따라서, VDM은 임의의 노이즈가 추가된 이미지($x_t$) 와 $t$ 로, 오리지널 이미지($x_0$) 를 신경망을 통해 예측하는 것으로 요약됩니다.**
- 그리고 이를 전체 ELBO 마지막 텀으로 표현해보면, 아래와 같다.

$$
\underset{\theta}{argmin}\,\mathbb{E}_{t\sim U\{2,T\}} \left[ \mathbb{E}_{q(x_t\vert x_0)} \,D_{KL}\,(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t)) \right]
$$

### 세 가지 동등한 해석
- 앞서 증명한 바와 같이, Variational Diffusion Model 은 단순히 신경망을 학습시켜 임의의 노이즈가 추가된 버전 $x_t$ 와 $t$에서 원래의 이미지 $x_0$ 를 예측하도록 하는 방식으로 학습 할 수 있다.
- $x_0$ 는 두 가지 다른 동등한 매개변수를 가지며, 이로 인해 두 가지 추가적인 해석이 가능하다.
- Reparameterization trick을 이용하여, $\mu_q(x_t, x_0)$ 를 다르게 표현 할 수 있다.

$$
\begin{aligned}
x_0 &= \frac{x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}} \quad \text{이므로,}
\\ \mu_q(x_t, x_0) &= \frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) x_0}{\left(1-\bar{\alpha}_t \right)}
\\ &= \frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + \sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t) \frac{x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}}{\left(1-\bar{\alpha}_t \right)}
\\ &= \frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t + (1-\alpha_t) \frac{x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon_0}{\sqrt{\alpha_t}}}{\left(1-\bar{\alpha}_t \right)}
\\ &= \frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) x_t}{\left(1-\bar{\alpha}_t \right)}  + \frac{(1-\alpha_t)x_t}{(1-\bar{\alpha}_t)\sqrt{\alpha_t}} - \frac{(1-\alpha_t)\sqrt{1- \bar{\alpha}_t}\epsilon_0}{(1-\bar{\alpha}_t)\sqrt{\alpha_t}}
\\ &= 
\left(\frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1})}{\left(1-\bar{\alpha}_t \right)}  
+ \frac{(1-\alpha_t)}{(1-\bar{\alpha}_t)\sqrt{\alpha_t}} \right) x_t
- \frac{(1-\alpha_t)\sqrt{1- \bar{\alpha}_t}}{(1-\bar{\alpha}_t)\sqrt{\alpha_t}} \epsilon_0
\\ &= 
\frac{1-\bar{\alpha}_t}{(1-\bar{\alpha}_t)\sqrt{\alpha_t}}  x_t
- \frac{1-\alpha_t}{\sqrt{1- \bar{\alpha}_t}\sqrt{\alpha_t}} \epsilon_0
\\ &= 
\frac{1}{\sqrt{\alpha_t}}  x_t
- \frac{1-\alpha_t}{\sqrt{1- \bar{\alpha}_t}\sqrt{\alpha_t}} \epsilon_0
\end{aligned}
$$

- 따라서, $\mu_\theta(x_t, t)$ 는 아래와 같이  $\epsilon_0$ 을 예측하는 방식으로 표현 할 수 있다.

$$
\mu_\theta(x_t,t) = \frac{1}{\sqrt{\alpha_t}}  x_t
- \frac{1-\alpha_t}{\sqrt{1- \bar{\alpha}_t}\sqrt{\alpha_t}} \hat{\epsilon}_\theta(x_t, t)
$$

- 이 식을 이용하여, $D_{KL}\,(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t))$을  풀어보면,

$$
\begin{aligned}
&\underset{\theta}{argmin}\,D_{KL}\,(q(x_{t-1}\vert x_t, x_0) \Vert p_\theta(x_{t-1}\vert x_t))
\\ &= \underset{\theta}{argmin}\,D_{KL} (N(x_{t-1}; \mu_q, \Sigma_q(t)) \Vert N(x_{t-1};\mu_\theta, \Sigma_q(t)))
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} \left[\Vert \mu_\theta - \mu_q \Vert^2_2\right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)} 
\left[ \left\Vert
\frac{1}{\sqrt{\alpha_t}}  x_t - \frac{1-\alpha_t}{\sqrt{1- \bar{\alpha}_t}\sqrt{\alpha_t}} \epsilon_0
- \frac{1}{\sqrt{\alpha_t}}  x_t + \frac{1-\alpha_t}{\sqrt{1- \bar{\alpha}_t}\sqrt{\alpha_t}} \hat{\epsilon}_\theta(x_t, t)
\right\Vert^2_2 \right]
\\ &= \underset{\theta}{argmin}\, \frac {1} {2\sigma^2_q(t)}  \frac{(1-\alpha_t)^2}{(1- \bar{\alpha}_t)\alpha_t}
\left[ \left\Vert
  \epsilon_0 - \hat{\epsilon}_\theta(x_t, t)
\right\Vert^2_2 \right]
\end{aligned}
$$

- 여기서 $\hat{\epsilon}_\theta(x_t, t)$ 는 $x_0$ 에서 $x_t$ 를 결정하는 소스 노이즈 $\epsilon \sim N(\epsilon; 0, I)$를 예측하게 학습하는 신경망이고, 따라서 원래 이미지 $x_0$ 를 예측하는 것과 노이즈를 예측하는 것이 동등하다는 것을 볼 수 있다.
- 몇 몇 연구에 의하면 노이즈를 예측하는 것이 더 나은 결과를 보인다고 한다.
- *정리해보면, 결국 주어진 $x_t$에 대하여  $\mu, x_0, \epsilon_0$ 계산 하는 것은 모두 동등하다고 할 수 있다.*


### Training
앞서, $x_t$에 대하여, 아래와 같이 정리하였다.

$$
x_t=\sqrt{\bar{\alpha}_t}\, x_0 + \sqrt{1 - \bar{\alpha}_t}\, \epsilon_0 \sim N\,(x_t; \sqrt{\bar{\alpha}_t}\, x_0, \sqrt{1 - \bar{\alpha}_t}\, I)
$$

따라서, 노이즈를 기반으로 Training 과정을 작성해보면 아래와 같다.

1. **repeat**
2. $x_0 \sim q(x_0)$
3. $t\sim Uniform(\{ 1,...,T \})$
4. $\epsilon \sim N(0,I)$
5. Take gradient decsent step on
    $\nabla_\theta \Vert \epsilon - \epsilon_\theta(x_t, t) \Vert^2$
    $= \nabla_\theta \Vert \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}\, x_0 + \sqrt{1 - \bar{\alpha}_t}, t) \, \epsilon \Vert^2$
6. **until** converged

### 코드와의 비교
- Diffusion 학습 코드는 아래와 같다. 

```
def train_step(self, images):
        self.optim.zero_grad()
        images = self.normalizer(images)
	    # 노이즈를 랜덤하게 샘플링
        noises = torch.randn_like(images)
        noises = noises.to(images.device)
        batch_size = images.shape[0]
        # time step을 랜덤하게 샘플링
        diffusion_times = torch.rand(size=[batch_size, 1, 1, 1])
        diffusion_times = diffusion_times.to(images.device)
        # time step으로 alpha bar, 1 - alpha bar 구함
        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)
        # x_t = \sqrt{\bar{\alpha}_t} + \sqrt{1 - \bar{\alpha}_t} noise
        noisy_images = signal_rates * images + noise_rates * noises
        # 모델로 노이즈를 계산
        pred_noises, pred_images = self.denoise(noisy_images, noise_rates, signal_rates, True)
	    # 노이즈 이미지와 실제 노이즈 간 Loss 측정 및 경사 하강법
        loss = self.criterion(noises, pred_noises)
        loss.backward()
        self.optim.step()

        self.update_ema(self.model, self.ema_model, self.ema_decay)

        return loss.item()

```

- 실제 코드를 보면, 유도 공식이 엄청 길었음에 비해, 학습은 매우 간단한 코드로 이루어짐을 알 수있다.
- 전체 코드는 https://github.com/joseph-jingi-jung/generative-dl-2nd/blob/main/diffusion.ipynb 에서 확인 할 수 있다.

